# Python SLAM Project

[![ROS 2 Humble](https://img.shields.io/badge/ROS2-Humble-blue)](https://docs.ros.org/en/humble/)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive **Simultaneous Localization and Mapping (SLAM)** implementation in Python with ROS 2 integration and Docker development environment. This project provides a complete SLAM framework with advanced computer vision techniques and flight integration capabilities for robotic applications.

## ğŸš€ Features

### Core SLAM Capabilities
- **Visual SLAM**: ORB feature-based visual odometry and mapping
- **Real-time Processing**: Optimized for real-time drone operations
- **Loop Closure Detection**: Advanced loop closure with pose graph optimization
- **3D Mapping**: Point cloud generation and occupancy grid mapping
- **Robust Localization**: Particle filter-based localization

### Aerial Drone Integration
- **Flight Control Integration**: Seamless integration with drone flight controllers
- **Altitude Management**: Automatic altitude control and safety monitoring
- **Emergency Handling**: Emergency landing and safety protocols
- **Competition-Ready**: Optimized for aerial drone competition requirements

### Professional Development Features
- **ROS 2 Integration**: Full ROS 2 Humble support with custom nodes
- **Docker Containerization**: Multi-stage Docker containers for development and deployment
- **Advanced Tooling**: VS Code integration with Copilot, multi-language support
- **CI/CD Pipeline**: GitHub Actions with automated testing and deployment
- **Code Quality**: Pre-commit hooks, linting, formatting, and type checking

## ğŸ“‹ Requirements

### System Requirements
- **OS**: Ubuntu 22.04 LTS (recommended) or compatible Linux distribution
- **Python**: 3.8 or higher
- **ROS 2**: Humble Hawksbill
- **Docker**: 20.10+ (optional, for containerized deployment)

### Hardware Requirements
- **CPU**: Multi-core processor (Intel i5/AMD Ryzen 5 or better)
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 20GB free space
- **Camera**: USB/CSI camera or drone camera system

## ï¿½ Quick Start

### Prerequisites
- Docker and Docker Compose
- VS Code (recommended for development)

### Setup Development Environment

1. **Navigate to Project Directory**
   ```bash
   cd python-slam
   ```

2. **Build Development Environment**
   ```bash
   ./scripts/dev.sh setup
   ```

3. **Enter Development Shell**
   ```bash
   ./scripts/dev.sh shell
   ```

4. **Build ROS Package**
   ```bash
   ./scripts/dev.sh build
   ```

5. **Run SLAM Node**
   ```bash
   ./scripts/dev.sh run
   ```

## ğŸ“ Project Structure

```
python-slam/
â”œâ”€â”€ src/python_slam/              # Main SLAM package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ slam_node.py              # Main ROS 2 SLAM node
â”‚   â”œâ”€â”€ basic_slam_pipeline.py    # Basic SLAM pipeline
â”‚   â”œâ”€â”€ feature_extraction.py     # ORB feature detection
â”‚   â”œâ”€â”€ pose_estimation.py        # Essential matrix & pose recovery
â”‚   â”œâ”€â”€ mapping.py                # Point cloud mapping
â”‚   â”œâ”€â”€ localization.py           # Particle filter localization
â”‚   â”œâ”€â”€ loop_closure.py           # Loop closure detection
â”‚   â””â”€â”€ flight_integration.py     # Drone flight integration
â”œâ”€â”€ docker/                       # Docker configuration
â”œâ”€â”€ scripts/                      # Development scripts
â”‚   â”œâ”€â”€ dev.sh                    # Main development script
â”‚   â””â”€â”€ setup.sh                  # Local setup script
â”œâ”€â”€ tests/                        # Test files
â”œâ”€â”€ Dockerfile                    # Multi-stage Docker build
â”œâ”€â”€ docker-compose.yml            # Development orchestration
â”œâ”€â”€ package.xml                   # ROS 2 package metadata
â”œâ”€â”€ setup.py                      # Python package setup
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ›  Development Workflow

### Available Commands

```bash
# Setup development environment
./scripts/dev.sh setup

# Enter development shell
./scripts/dev.sh shell

# Build ROS package
./scripts/dev.sh build

# Run SLAM node
./scripts/dev.sh run

# Stop all containers
./scripts/dev.sh stop

# View logs
./scripts/dev.sh logs
```

### Development Container Features

- **Base Environment**: ROS 2 Humble on Ubuntu 22.04
- **Development Tools**:
  - vim, nano, gdb, valgrind
  - htop, tree, tmux
  - black, pylint, pytest
  - ipython, jupyter
- **Pre-installed Packages**:
  - OpenCV, NumPy, SciPy, Matplotlib
  - ROS 2 CV Bridge, Geometry Messages
  - All SLAM dependencies

## ğŸ§© SLAM Components

### 1. Feature Extraction (`feature_extraction.py`)
- **Algorithm**: ORB (Oriented FAST and Rotated BRIEF)
- **Features**: Scale and rotation invariant
- **Output**: Keypoints and descriptors for image matching

### 2. Pose Estimation (`pose_estimation.py`)
- **Method**: Essential matrix decomposition
- **Process**: RANSAC-based outlier rejection
- **Output**: Camera rotation and translation

### 3. Mapping (`mapping.py`)
- **Structure**: 3D point cloud generation
- **Triangulation**: Stereo vision-based depth estimation
- **Optimization**: Bundle adjustment for accuracy

### 4. Localization (`localization.py`)
- **Algorithm**: Particle filter
- **Features**: Probabilistic state estimation
- **Robustness**: Handles noise and uncertainty

### 5. Loop Closure (`loop_closure.py`)
- **Detection**: Visual similarity matching
- **Verification**: Geometric consistency checks
- **Correction**: Graph optimization for drift correction

### 6. Flight Integration (`flight_integration.py`)
- **UAV Support**: Drone-specific SLAM adaptations
- **Sensors**: IMU and visual odometry fusion
- **Control**: Real-time positioning for flight control

## ğŸš Usage

### Basic SLAM Pipeline

```python
from python_slam import BasicSlamPipeline
import cv2

# Initialize SLAM pipeline
slam = BasicSlamPipeline()

# Process video stream
cap = cv2.VideoCapture(0)
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Process frame through SLAM pipeline
    pose, map_points = slam.process_frame(frame)

    # Display results
    cv2.imshow('SLAM', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### ROS 2 Integration

```bash
# Build ROS 2 workspace (inside container)
source /opt/ros/humble/setup.bash
colcon build --packages-select python_slam
source install/setup.bash

# Launch SLAM node
ros2 run python_slam slam_node

# With custom parameters
ros2 run python_slam slam_node --ros-args --log-level info
```

### Individual Components

```python
# Feature extraction
from python_slam.feature_extraction import FeatureExtraction
fe = FeatureExtraction()
features = fe.extract_features(image)

# Pose estimation
from python_slam.pose_estimation import PoseEstimation
pe = PoseEstimation()
pose = pe.estimate_pose(prev_frame, curr_frame)

# Mapping
from python_slam.mapping import Mapping
mapper = Mapping()
mapper.update(pose, features)
point_cloud = mapper.get_point_cloud()
```

## ğŸ§ª Testing

### Run Tests (in Development Container)

```bash
# Enter development container
./scripts/dev.sh shell

# Run all tests
source /opt/ros/humble/setup.bash
source /workspace/install/setup.bash
python -m pytest tests/ -v

# Test individual components
python test_slam_modules.py
```

### Test Coverage

- Feature extraction validation
- Pose estimation accuracy
- Mapping consistency
- Localization performance
- Loop closure detection
- Integration testing

## ğŸ“Š Performance

### Benchmarks

- **Feature Detection**: ~90 keypoints per frame
- **Processing Speed**: Real-time capable
- **Memory Usage**: Optimized for embedded systems
- **Accuracy**: Sub-meter localization precision

### Optimization Tips

- Use GPU acceleration for OpenCV operations
- Reduce feature count for real-time operation
- Enable multithreading for parallel processing
- Use Docker for consistent performance

## ğŸ”§ Configuration

### Docker Configuration

- **Development**: Full development environment with tools
- **Production**: Optimized runtime environment
- **Runtime**: Minimal environment for deployment

### ROS 2 Integration

- **Node**: `slam_node` - Main SLAM processing node
- **Topics**:
  - `/camera/image_raw` - Input camera feed
  - `/slam/pose` - Estimated pose output
  - `/slam/map` - Generated point cloud map
- **Services**: Configuration and control services

### Environment Variables

Key environment variables can be set in `.env` file:

```bash
# ROS 2 Configuration
ROS_DOMAIN_ID=0
ROS_LOCALHOST_ONLY=1

# SLAM Parameters
MAX_FEATURES=1000
QUALITY_LEVEL=0.01
MIN_DISTANCE=10
LOOP_CLOSURE_ENABLED=true
MAPPING_ENABLED=true
```

## ğŸš€ Development

### Development Workflow

```bash
# Format code (inside container)
black src/python_slam/
pylint src/python_slam/

# Run tests
python -m pytest tests/ -v

# Complete development workflow
./scripts/dev.sh shell
```

### Adding New Features

1. Create feature branch: `git checkout -b feature/new-feature`
2. Implement changes with tests
3. Run quality checks inside development container
4. Submit pull request

### Code Quality Standards

- **Black** for code formatting
- **Pylint** for linting
- **Pytest** for testing
- **Docker** for consistent environment

## ï¿½ Drone Integration

### Supported Platforms

- MAVLink-compatible drones
- PX4 flight controller
- ArduPilot systems

### Features

- Real-time pose estimation
- Visual-inertial odometry
- Autonomous navigation support
- Obstacle avoidance integration

## ğŸ“š Documentation

### Key References

- [ROS 2 Humble Documentation](https://docs.ros.org/en/humble/)
- [OpenCV SLAM Tutorials](https://docs.opencv.org/)
- [Visual SLAM Algorithms](https://github.com/younan-l/awesome-slam)

### Research Papers

- MonoSLAM: Real-time single camera SLAM
- ORB-SLAM2: An Open-Source SLAM System
- Visual-Inertial Monocular SLAM

## ğŸ¤ Contributing

### Development Setup

1. Fork the repository
2. Create development environment: `./scripts/dev.sh setup`
3. Create feature branch
4. Make changes with tests
5. Submit pull request

### Reporting Issues

Please use GitHub Issues with:

- Clear description
- Steps to reproduce
- Expected vs actual behavior
- System information

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¯ Roadmap

### Current Features âœ…

- Multi-stage Docker development environment
- ROS 2 SLAM node implementation
- Feature extraction and matching
- Pose estimation and mapping
- Development workflow automation

### Upcoming Features ğŸ”„

- Real-time optimization
- Multi-sensor fusion
- Advanced loop closure
- Deep learning integration
- Cloud deployment support

### Future Enhancements ğŸ”®

- Semantic SLAM
- Neural network features
- Edge computing optimization
- Multi-robot collaboration
- AR/VR integration

## ğŸ† Acknowledgments

- **OpenCV** for computer vision algorithms
- **ROS 2** for robotics middleware
- **NumPy/SciPy** for numerical computing
- **Open Source Community** for inspiration and tools

## ğŸ“ Support

For questions and support:

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: Project documentation
- **Examples**: Test and example files

---

**Happy SLAMming! ğŸ¯**
